# -*- coding: utf-8 -*-
"""Trying NER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZN4evbysZdjuUPmruOX1_aYdcPO0XR5F
"""

!pip install NERDA

from NERDA.datasets import get_conll_data, download_conll_data
download_conll_data()
training = get_conll_data('train')
validation = get_conll_data('valid')

tag_scheme = [
'B-PER',
'I-PER',
'B-ORG',
'I-ORG',
'B-LOC',
'I-LOC',
'B-MISC',
'I-MISC'
]

transformer = 'bert-base-multilingual-uncased'

# hyperparameters for network
dropout = 0.1
# hyperparameters for training
training_hyperparameters = {
'epochs' : 4,
'warmup_steps' : 500,                                                   
'train_batch_size': 13,                                         
'learning_rate': 0.0001
}

from NERDA.models import NERDA
model = NERDA(
dataset_training = training,
dataset_validation = validation,
tag_scheme = tag_scheme, 
tag_outside = 'O',
transformer = transformer,
dropout = dropout,
hyperparameters = training_hyperparameters
)

model.train()

test = get_conll_data('test')

model.evaluate_performance(test)

import nltk 
nltk.download('punkt')
#model.predict_text('Cristiano Ronaldo plays for Juventus FC')
model.predict_text('Jim bought 300 shares of Acme Corp. in 2006. And producing an annotated block of text that highlights the names of entities: In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.State-of-the-art NER systems for English produce near-human performance. For example, the best system entering MUC-7 scored 93.39% of F-measure while human annotators scored 97.60% and 96.95%.[1][2]')



